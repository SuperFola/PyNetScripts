#!/usr/bin/env python3

from bs4 import BeautifulSoup, SoupStrainer
import requests
import urllib.request as urlreq
import sys


url = input("url> ") if len(sys.argv) == 1 else sys.argv[1]

page = requests.get(url)
data = page.text
soup = BeautifulSoup(data, features="html.parser")

saved = []

for img in soup.find_all('img'):
    src = img.get('src')
    if src[0] == '/':
        src = url + src
    name = src.replace('/', '').replace(':', '').replace('&', '').lower().split('?')[0]
    i = 0
    while (name if i == 0 else name + str(i)) in saved:
        i += 1
    saved.append(name + str(i))
    if i != 0:
        name = name.split('.')
        if len(name) > 1:
            name[-2] += str(i)
        else:
            name[-1] += str(i)
        name = '.'.join(name)
    urlreq.urlretrieve(src, name)
